{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ad4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from utils.inkml2img import convert_dir\n",
    "from tqdm.auto import tqdm\n",
    "from data.dataset import Im2LatexDataset\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from model.vit import ViT\n",
    "import lightning as L\n",
    "import wandb\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, pre_tokenizers\n",
    "from tokenizers.models import BPE\n",
    "from model.decoder import Decoder, DecoderAttention, DecoderTransformerBlock\n",
    "from model.model import Img2MathModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79858ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanh/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:51: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.0.4, which is newer than your current Lightning version: v2.0.3\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "1 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "2 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "3 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "4 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "5 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "6 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "7 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "8 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "9 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "10 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "11 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "12 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "13 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "14 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "15 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "16 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "17 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "18 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "19 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "20 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "21 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "22 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "23 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "24 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "25 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "26 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "27 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "28 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "29 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "30 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "31 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "32 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "33 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "34 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "35 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "36 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "37 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "38 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "39 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "40 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "41 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "42 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "43 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "44 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "45 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "46 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "47 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "48 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "49 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "50 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "51 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "52 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "53 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "54 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "55 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "56 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "57 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "58 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "59 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "60 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "61 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "62 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "63 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "64 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "65 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "66 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "67 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "68 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "69 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "70 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "71 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "72 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "73 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "74 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "75 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "76 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "77 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "78 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "79 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "80 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "81 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "82 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "83 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "84 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "85 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "86 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "87 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "88 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "89 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "90 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "91 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "92 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "93 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "94 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "95 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "96 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "97 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "98 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "99 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "100 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "101 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "102 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "103 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "104 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "105 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "106 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "107 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "108 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "109 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "110 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "111 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "112 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "113 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "114 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "115 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "116 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "117 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "118 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "119 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "120 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "121 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "122 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "123 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "124 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "125 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "126 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "127 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "128 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "129 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "130 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "131 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "132 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "133 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "134 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "135 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "136 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "137 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "138 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "139 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "140 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "141 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "142 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "143 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "144 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "145 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "146 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "147 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "148 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "149 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "150 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "151 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "152 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "153 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "154 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "155 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "156 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "157 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "158 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "159 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "160 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "161 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "162 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "163 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "164 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "165 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "166 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "167 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "168 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "169 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "170 torch.Size([256, 2160]) torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "172 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "173 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "174 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "175 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "176 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "177 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "178 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "179 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "180 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "181 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "182 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "183 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "184 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "185 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "186 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "187 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "188 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "189 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "190 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "191 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "192 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "193 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "194 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "195 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "196 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "197 torch.Size([256, 2160]) torch.Size([2, 256])\n",
      "198 torch.Size([256, 2160]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_dims = [256, 256]\n",
    "data = Im2LatexDataset(path_to_data=\"../data/\",\n",
    "                       tokenizer=\"../data/tokenizer.json\", img_dims=img_dims, batch_size=2, device=torch.device('cpu'))\n",
    "batch = next(iter(data.train))\n",
    "img, label = batch\n",
    "vocab_size = len(data.tokenizer.get_vocab())\n",
    "model = Img2MathModel.load_from_checkpoint('../train/img2math/362edsd8/checkpoints/epoch=9-step=65180.ckpt', map_location=torch.device('cpu'))\n",
    "model(img)\n",
    "#model.eval()\n",
    "#logits, _ = model(img)\n",
    "#torch.argmax(logits)\n",
    "#val_imgs = img\n",
    "#model.training_step(batch, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa7a840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 #preds = [model.generate(img) for img in val_imgs]</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>tokenizer = PreTrainedTokenizerFast(tokenizer_file=<span style=\"color: #808000; text-decoration-color: #808000\">'../data/tokenizer.json'</span>, padding_sid    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8 seq = model.generate(val_imgs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>decode(tokenizer, seq)                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'val_imgs'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m8\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m#preds = [model.generate(img) for img in val_imgs]\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0mtokenizer = PreTrainedTokenizerFast(tokenizer_file=\u001b[33m'\u001b[0m\u001b[33m../data/tokenizer.json\u001b[0m\u001b[33m'\u001b[0m, padding_sid    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8 seq = model.generate(val_imgs[\u001b[94m0\u001b[0m])                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0mdecode(tokenizer, seq)                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'val_imgs'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode(tokenizer, sequence):\n",
    "    dec = [tokenizer.decode(tok) for tok in sequence]\n",
    "    return ''.join([detok.replace('Ġ', ' ') for detok in dec])\n",
    "\n",
    "#preds = [model.generate(img) for img in val_imgs]\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file='../data/tokenizer.json', padding_side='left')\n",
    "\n",
    "seq = model.generate(val_imgs[0])\n",
    "decode(tokenizer, seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca529c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbaolong\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230706_213920-0jvbqwtx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/baolong/img2math/runs/0jvbqwtx' target=\"_blank\">zesty-eon-38</a></strong> to <a href='https://wandb.ai/baolong/img2math' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/baolong/img2math' target=\"_blank\">https://wandb.ai/baolong/img2math</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/baolong/img2math/runs/0jvbqwtx' target=\"_blank\">https://wandb.ai/baolong/img2math/runs/0jvbqwtx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | ViT     | 8.9 M \n",
      "1 | decoder | Decoder | 14.9 M\n",
      "------------------------------------\n",
      "23.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.9 M    Total params\n",
      "95.443    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanh/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/dylanh/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb23cd01263e4904ac33b2a3a0e61203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563ac08e8d4f4e6295e0c9219f297db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.229 MB of 0.229 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁</td></tr><tr><td>global_step</td><td>▁█</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/loss_epoch</td><td>▁</td></tr><tr><td>val/loss_step</td><td>▂▄▃▃▃▂▃▃▆▂▄▂▂▂▃▃█▁▂▂▁▃▄▃▂▆▂▂▁▃▃▂▄▃▃▂▇▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>global_step</td><td>10</td></tr><tr><td>train/loss</td><td>0.00864</td></tr><tr><td>trainer/global_step</td><td>9</td></tr><tr><td>val/loss_epoch</td><td>0.44301</td></tr><tr><td>val/loss_step</td><td>0.3337</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-eon-38</strong> at: <a href='https://wandb.ai/baolong/img2math/runs/0jvbqwtx' target=\"_blank\">https://wandb.ai/baolong/img2math/runs/0jvbqwtx</a><br/>Synced 6 W&B file(s), 20 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230706_213920-0jvbqwtx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOKENIZER_FILE = '../data/tokenizer.json'\n",
    "\n",
    "def decode(tokenizer, sequence):\n",
    "    dec = [tokenizer.decode(tok) for tok in sequence]\n",
    "    return ''.join([detok.replace('Ġ', ' ') for detok in dec])\n",
    "\n",
    "class ImagePredictionLogger(L.Callback):\n",
    "    \n",
    "    def __init__(self, val_samples, num_samples=10):\n",
    "        super().__init__()\n",
    "        self.tokenizer = PreTrainedTokenizerFast(tokenizer_file=TOKENIZER_FILE, padding_side='left')\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "        self.val_imgs = self.val_imgs[:num_samples]\n",
    "        self.val_labels = [decode(self.tokenizer, label) for label in self.val_labels['input_ids'][:num_samples]]\n",
    "\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "\n",
    "        pred_tokens = [pl_module.generate(x) for x in val_imgs]\n",
    "        preds = [decode(self.tokenizer, pred) for pred in pred_tokens]\n",
    "\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\": [wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\")\n",
    "                         for x, pred, y in zip(val_imgs, preds, self.val_labels)],\n",
    "            \"global_step\": trainer.global_step\n",
    "        })\n",
    "\n",
    "logger = WandbLogger(project='img2math')\n",
    "\n",
    "trainer = L.Trainer(limit_train_batches=10, max_epochs=1, log_every_n_steps=10, deterministic=True,\n",
    "                    logger=logger, accelerator='mps', callbacks=[ImagePredictionLogger(batch)])\n",
    "\n",
    "trainer.fit(model, data.train, data.test)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f7744de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mem usage: 1310720\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n",
      "mem usage: 1835008\n",
      "mem usage: 1572864\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps')\n",
    "a = torch.randn(256, 512).to(device)\n",
    "\n",
    "for i in range(100):\n",
    "    b = torch.randn(256, 512).to(device)\n",
    "    c = a @ b.T\n",
    "    print(f\"mem usage: {torch._C._mps_currentAllocatedMemory()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e539a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
